# nGPT-BART-PEGASUS-efficiency-study

### Abstract
The goal of our project is to evaluate and compare the performance of nGPT, Nvidia's model, against two state-of-the-art abstractive text summarization models: PEGASUS (Google) and BART (Facebook). Our primary focus is on assessing nGPT's claims of achieving 4-20x faster training and improved stability for Large Language Models (LLMs) in the context of abstractive text summarization.

### Key Layout and Project Structure



### How to run


### Credits
